# Large and Fast: Exploiting Memory Hierarchy

컴퓨터는 크게 Processor, Memory, I-O Devices로 나뉘는데 이 장에서는 메모리에 대해 배웁니다. 메모리는 캐시 메모리, 메인 메모리, 그리고 세컨더리 메모리로 나누어진다. 우린 앞의 두 메모리를 배울 겁니다



## Memory Technologies

Static RAM(SRAM): 빠르지만 비싸다

Dynamic RAM(DRAM): 상대적으로 느리지만 싸다

(Flash Memory)

Magnetic Dist(HDD): 느리지만 더 싸다

Ideal Memory: SRAM의 성능과 HDD의 가격...(양심 다이죠부?)



memory wall: 성능 향상이 메모리(느려!) 때문에 제약을 받는 것. 프로세서보다는 메모리 때문에 성능 향상이 더 더뎌지고 있다.



## Cache

Principle of Locality ★
: 프로그램의 특정한 부분을 다른 부분에 비해 더 자주, 많이 사용하는 현상

why? 프로그램은 기본적으로 반복문을 많이 사용하게 된다. 그 반복되는 부분을 자주 사용한다는 뜻이겠지?

* Temporal locality
  : 내가 한 번 엑세스한 메모리를 금세 또 엑세스
* Spatioal locality
  : 내가 한 번 엑세스한 메모리 '주변' 메모리에 금세 엑세스

이 locality를 잘 활용하면 빠르게 사용할 수 있다



모든 건 disk에 저장되어 있다가 엑세스하면 DRAM memory에 올라오게 된다. 또 그 일부분이 작은 SRAM으로 올라오게 된다. 이걸 바로 cache memory라고 한다. 이렇게 캐시 메모리는 점점 CPU에 가깝게 오게 된다.



### Memory Hierarchy Levels 용어들

* block(a.k.a. line)
  : 인접한 두 영역에서 데이터를 주고받는 단위. 프로세서와 캐시 메모리 사이 주고받는 건 32bit 기준 word라고 하고, 캐시 메모리와 메인 메모리(DRAM) 사이 주고 받는 걸 block이라 하는 것! 하나의 word일 수도, 여러 개의 word일 수도 있다. 
* hit
  : 내가 접근하고자 하는 메모리가 upper level(=캐시 메모리)에 있을 때를 일컫는다. 
  * hit ratio = hits / accesses
* miss
  : 만약 upper level에 없다면 lower level(=메인 메모리)까지 가서 그걸 캐시 메모리로 올려야겠지. 그래서 아직 upper level에 없고 lower level에 있는 걸 miss라고 한다.
  * miss ratio = miss / accesses
    &rarr; miss ratio + hit ratio = 1
  * miss pealty: lower level에서 upper level까지 데이터를 올리는 시간



### Memory Hierarchy

![Memory Hierarchy](https://computerscience.chemeketa.edu/cs160Reader/_images/Memory-Hierarchy.jpg)

* 요즘은 보통 캐시 메모리가 level 3(L3)까지 있고, cache의 발음이 cash와 같기 때문에 보통 표기를 L1$, L2$, L3$로 쓰기도 한다. 
* inclusive: 밑으로 갈수록 access time이 늘어나고, 크기도 커진다. secondary memory의 subset이 main memory고, main memory의 subset이 L3$고, L3$의 subset이 L2$고... 이런 특성을 가진다.
* 보통 processor-L1$ 간의 word가 4bit(32bit) 또는 8bit(64bit) / cache 간에 주고받는 건 8~32bit의 1개의 block, 그리고 제일 하단 cache와 main memory 간에 주고받는 건 1~4 block이다. 마지막으로 main memory와 secondary memory 간에는 1024+bytes... 보통은 4KB라고 한다. (cf. 1KB = 1024byte)



### DRAM technology

* DRAM은 1개의 transistor를 쓴다(SRAM의 경우 3개).
* refresh: 시간이 지나면 거기 있는 데이터가 사라지기 때문에 주기적으로 똑같은 데이터를 씌워줘야 한다. 보통 DRAM의 row 단위로 읽어서 다시 쓴다. DRAM이 넴모넴모해서
* DRAM은 row를 먼저 읽고 그 다음 column을 읽는다. 우리 알고에서 (3, 2)라면 3이 row고 2가 column인 것처럼 row를 먼저 계산한다는 뜻
* Burst mode
  : 만약 row가 같은 연속된 데이터들을 가져오려 하면 row 한 번만 읽고 column만 쭉쭉 옮기면 되니까 latency가 줄어든다. (column이 같고 row가 다르다면 읽는 순서가 row1-column1-row2-column1-row3-column1 처럼 column이 같다 해서 뭔가 특별히 줄어드는 게 없음) 이렇게 접근하는 방법을 burst mode라고 한다.
* DDR(Double Data Rate) DRAM
  : 우리가 보통 clock을 그려보면 올라갔다 내려갔다를 반복하는데 보통의 rising edges에서만 데이터를 주고받는 게 아니라 falling edges에서도 데이터를 주고받는 걸 말한다.
* QDR(Quad Data Rate) DRAM
  : DRAM에 데이터 주고 받는 포트를 하나 더 만들어서 DDR*2해서 쿼드가 되는 거



### DRAM Performance Factors

* Row buffer
  : DRAM에 있는 워드의 값을 refresh하기 위해서 buffer에 read data를 따로 저장해두고 DRAM은 refresh시킨다. 
* Synchronous DRAM (SDRAM)
  : DRAM이 clock과 동기화돼서 데이터를 주고받을 수 있게 하는 것. 어떻게 하냐면 burst mode로 해서 데이터 각각의 주소를 보낼 필요 없이 하나의 주소만 있으면 column만 옮기면 되니까 성능 향상을 꾀할 수 있다
* DRAM banking
  : DRAM에서 읽고 쓰기를 독립적으로 가능하게 해서 동시에 읽고 쓰기를 가능하게 하는 것.



### Main Memory

* 얘로 보통 DRAM을 쓰는데 width가 고정되어 있고(ex. 1word) SDRAM이다. 근데 보통 이 bus clock은 CPU clock보다 느리다.
* 예를 들자면 이런 거다. 주소 전송하는 데에 1 bus cycle을, 그 주소에 있는 데이터에 접근하는 데에 15 bus cycle을, 그리고 그 읽은 데이터를 cache로 주는 데에 1 bus cycle이 걸린다.  근데 보통 1 block = 4 words인 반면 DRAM의 width는 1 word 정도라서 이 bus cycle들을 1이라고 1만큼 소요하는 게 아니라 miss penalty = 1 + 4*15 + 4\*1 = 65 bus cycles가 걸린다. 그러다보니 band width도 16bytes / 65 cycles = 0.25 B/cycle이 된다.



### Increasing Memory Bandwidth

![img](https://www.cs.umd.edu/users/meesh/cmsc411/website/projects/ramguide/system/Diagram.jpg)

* 우리가 여태 봤던 건 가장 왼쪽의 memory organization이다. 1-word-wide라서 홀쭉함...
* 근데 만약 cache~memory까지 4-word-wide로 만들어진 wider memory organization이라면? 아까의 경우에 1 + 15 + 1 = 17 bus cycle이 걸리게 된다. band width = 16 bytes / 17 cycles = 0.94 B/cycle이 된다는 말씀.
* 그렇다면 세 번째 경우인 interleaved memory organization은 뭐냐면 1과 2의 절충형이라고 볼 수 있다. 독립적으로 읽고 쓰기가 가능한 memory bank가 4개고 bus는 1-word-wide임. 그래서 1 + 15 + 4*1 = 20 bus cycles가 되고 bandwidth = 16 bytes / 20 cycles = 0.8 B/cycle이 된다.
* 근데 2가 월등히 좋은 게 아닌게 bus가 4-word-wide라서 리소스를 훨씬 많이 쓰게 되는 반면 3은 1-word-wide라서 리소스를 덜 쓰게 된다. 그럼에도 불구하고 2와 3의 성능이 또이또이하기 때문에 요즘은 대부분 3을 채택하고 있다. 특히 SSD에서 많이 쓴다. 











